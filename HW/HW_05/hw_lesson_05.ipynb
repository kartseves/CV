{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5e8caa4",
   "metadata": {},
   "source": [
    "## Задание  \n",
    "Обучить детектор объектов с помощью TensorFlow Object Detection API  \n",
    "Библиотеки: [Python, Tensorflow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d81a655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2042b3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Определим каталоги\n",
    "\n",
    "# Путь к корневой папке\n",
    "ROOT_DIR = os.path.abspath('.')\n",
    "\n",
    "# Путь к локальной версии репозитория keras-retinanet\n",
    "KERAS_RETINANET_PATH = os.path.join(ROOT_DIR, \"keras-retinanet\")\n",
    "\n",
    "# Ссылка на скачивание модели\n",
    "COCO_MODEL_URL = \"https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5\"\n",
    "# Путь к предобученной модели\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"resnet50_coco_best_v2.1.0.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb03a35a",
   "metadata": {},
   "source": [
    "## Загрузка и подготовка библиотеки keras-retinanet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ed6174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(KERAS_RETINANET_PATH):\n",
    "    !git clone https://github.com/fizyr/keras-retinanet.git\n",
    "    !cd keras-retinanet \\\n",
    "        && git reset --hard abe89380835bc06dff3b97e69fa2b19dd7fd97a8 \\\n",
    "        && pip install . \\\n",
    "        && python setup.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeeca15",
   "metadata": {},
   "source": [
    "## Загрузка предобученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b08be607",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    with urllib.request.urlopen(COCO_MODEL_URL) as resp, open(COCO_MODEL_PATH, 'wb') as out:\n",
    "        shutil.copyfileobj(resp, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ee8796",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120648eb",
   "metadata": {},
   "source": [
    "Использованы материалы статьи https://danielcorcoranssql.wordpress.com/2019/04/19/keras-retinanet-sea-turtle-training-detection/ и данные репозитория https://github.com/danielc92/oidv4-sea-turtles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db50c1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "\n",
    "DATASET_DIR = './content/oidv4-sea-turtles/TRAIN/'\n",
    "ANNOTATIONS_FILE = 'annotations.csv'\n",
    "CLASSES_FILE = 'classes.csv'\n",
    "\n",
    "annotations = []\n",
    "classes = set([])\n",
    "\n",
    "for xml_file in [f for f in os.listdir(DATASET_DIR) if f.endswith(\".xml\")]:\n",
    "    tree = ET.parse(os.path.join(DATASET_DIR, xml_file))\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    file_name = None\n",
    "    \n",
    "    for elem in root:\n",
    "        if elem.tag == 'filename':\n",
    "            file_name = os.path.join(DATASET_DIR, elem.text)\n",
    "            \n",
    "        if elem.tag == 'object':\n",
    "            obj_name = None\n",
    "            coords = []\n",
    "            \n",
    "            for subelem in elem:\n",
    "                if subelem.tag == 'name':\n",
    "                    obj_name = subelem.text\n",
    "                if subelem.tag == 'bndbox':\n",
    "                    for subsubelem in subelem:\n",
    "                        coords.append(subsubelem.text)\n",
    "            \n",
    "            item = [file_name] + coords + [obj_name]\n",
    "            annotations.append(item)\n",
    "            classes.add(obj_name)\n",
    "            \n",
    "with open(ANNOTATIONS_FILE, 'w') as f:\n",
    "    for line in annotations:\n",
    "        f.write('{}\\n'.format(\",\".join(line)))\n",
    "    \n",
    "with open(CLASSES_FILE, 'w') as f:\n",
    "    for i, line in enumerate(classes):\n",
    "        f.write('{},{}\\n'.format(line,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4856be44",
   "metadata": {},
   "source": [
    "## Обучение модели для детектирования объектов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1ab0aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61adf54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404c3818",
   "metadata": {},
   "source": [
    "На текущей версии TF получаем ошибку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d274b76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model, this may take a second...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-19 18:08:06.578423: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found\n",
      "2022-07-19 18:08:06.578454: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-19 18:08:06.581099: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: ITSK-R910T6CC\n",
      "2022-07-19 18:08:06.581172: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: ITSK-R910T6CC\n",
      "2022-07-19 18:08:06.582520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Downloads\\CV\\HW\\HW_05\\keras-retinanet\\keras_retinanet\\bin\\train.py\", line 530, in <module>\n",
      "    main()\n",
      "  File \"C:\\Users\\User\\Downloads\\CV\\HW\\HW_05\\keras-retinanet\\keras_retinanet\\bin\\train.py\", line 483, in main\n",
      "    model, training_model, prediction_model = create_models(\n",
      "  File \"C:\\Users\\User\\Downloads\\CV\\HW\\HW_05\\keras-retinanet\\keras_retinanet\\bin\\train.py\", line 114, in create_models\n",
      "    model          = model_with_weights(backbone_retinanet(num_classes, num_anchors=num_anchors, modifier=modifier), weights=weights, skip_mismatch=True)\n",
      "  File \"C:\\Users\\User\\Downloads\\CV\\HW\\HW_05\\keras-retinanet\\keras_retinanet\\bin\\..\\..\\keras_retinanet\\models\\resnet.py\", line 38, in retinanet\n",
      "    return resnet_retinanet(*args, backbone=self.backbone, **kwargs)\n",
      "  File \"C:\\Users\\User\\Downloads\\CV\\HW\\HW_05\\keras-retinanet\\keras_retinanet\\bin\\..\\..\\keras_retinanet\\models\\resnet.py\", line 99, in resnet_retinanet\n",
      "    resnet = keras_resnet.models.ResNet50(inputs, include_top=False, freeze_bn=True)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras_resnet\\models\\_2d.py\", line 188, in ResNet50\n",
      "    return ResNet(inputs, blocks, numerical_names=numerical_names, block=keras_resnet.blocks.bottleneck_2d, include_top=include_top, classes=classes, *args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras_resnet\\models\\_2d.py\", line 66, in ResNet\n",
      "    x = keras_resnet.layers.BatchNormalization(axis=axis, epsilon=1e-5, freeze=freeze_bn, name=\"bn_conv1\")(x)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\__autograph_generated_filectnc0w4w.py\", line 13, in tf__call\n",
      "    retval_ = ag__.converted_call(ag__.converted_call(ag__.ld(super), (ag__.ld(BatchNormalization), ag__.ld(self)), None, fscope).call, tuple(ag__.ld(args)), dict(training=ag__.not_(ag__.ld(self).freeze), **ag__.ld(kwargs)), fscope)\n",
      "TypeError: Exception encountered when calling layer \"bn_conv1\" (type BatchNormalization).\n",
      "\n",
      "in user code:\n",
      "\n",
      "    File \"C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras_resnet\\layers\\_batch_normalization.py\", line 17, in call  *\n",
      "        return super(BatchNormalization, self).call(training=(not self.freeze), *args, **kwargs)\n",
      "\n",
      "    TypeError: dict() got multiple values for keyword argument 'training'\n",
      "\n",
      "\n",
      "Call arguments received by layer \"bn_conv1\" (type BatchNormalization):\n",
      "  • args=('tf.Tensor(shape=(None, None, None, 64), dtype=float32)',)\n",
      "  • kwargs={'training': 'None'}\n"
     ]
    }
   ],
   "source": [
    "!python keras-retinanet/keras_retinanet/bin/train.py \\\n",
    "    --random-transform \\\n",
    "    --weights \"./resnet50_coco_best_v2.1.0.h5\" \\\n",
    "    --steps 100 \\\n",
    "    --epochs 20 \\\n",
    "    csv \"annotations.csv\" \"classes.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e53bd96",
   "metadata": {},
   "source": [
    "К сожалению победить ошибку не удалось, в том числе при использовании %tensorflow_version 1.x в коллабе получаем ошибку:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe5827e",
   "metadata": {},
   "source": [
    "Using TensorFlow backend.\n",
    "Creating model, this may take a second...\n",
    "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
    "Instructions for updating:\n",
    "If using Keras pass *_constraint arguments to layers.\n",
    "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
    "\n",
    "Traceback (most recent call last):\n",
    "  File \"keras-retinanet/keras_retinanet/bin/train.py\", line 530, in <module>\n",
    "    main()\n",
    "  File \"keras-retinanet/keras_retinanet/bin/train.py\", line 490, in main\n",
    "    config=args.config\n",
    "  File \"keras-retinanet/keras_retinanet/bin/train.py\", line 114, in create_models\n",
    "    model          = model_with_weights(backbone_retinanet(num_classes, num_anchors=num_anchors, modifier=modifier), weights=weights, skip_mismatch=True)\n",
    "  File \"keras-retinanet/keras_retinanet/bin/train.py\", line 75, in model_with_weights\n",
    "    model.load_weights(weights, by_name=True, skip_mismatch=skip_mismatch)\n",
    "  File \"/tensorflow-1.15.2/python3.7/keras/engine/saving.py\", line 492, in load_wrapper\n",
    "    return load_function(*args, **kwargs)\n",
    "  File \"/tensorflow-1.15.2/python3.7/keras/engine/network.py\", line 1227, in load_weights\n",
    "    reshape=reshape)\n",
    "  File \"/tensorflow-1.15.2/python3.7/keras/engine/saving.py\", line 1262, in load_weights_from_hdf5_group_by_name\n",
    "    original_keras_version = f.attrs['keras_version'].decode('utf8')\n",
    "AttributeError: 'str' object has no attribute 'decode'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b51f31",
   "metadata": {},
   "source": [
    "## Конвертация обученной модели для инференса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ce2bd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-19 18:08:15.686435: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found\n",
      "2022-07-19 18:08:15.686465: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-19 18:08:15.689730: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: ITSK-R910T6CC\n",
      "2022-07-19 18:08:15.689791: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: ITSK-R910T6CC\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\Downloads\\CV\\HW\\HW_05\\keras-retinanet\\keras_retinanet\\bin\\convert_model.py\", line 97, in <module>\n",
      "    main()\n",
      "  File \"C:\\Users\\User\\Downloads\\CV\\HW\\HW_05\\keras-retinanet\\keras_retinanet\\bin\\convert_model.py\", line 75, in main\n",
      "    model = models.load_model(args.model_in, backbone_name=args.backbone)\n",
      "  File \"C:\\Users\\User\\Downloads\\CV\\HW\\HW_05\\keras-retinanet\\keras_retinanet\\bin\\..\\..\\keras_retinanet\\models\\__init__.py\", line 87, in load_model\n",
      "    return keras.models.load_model(filepath, custom_objects=backbone(backbone_name).custom_objects)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\saving\\save.py\", line 206, in load_model\n",
      "    raise IOError(f'No file or directory found at {filepath_str}')\n",
      "OSError: No file or directory found at 'snapshots/resnet50_csv_20.h5'\n"
     ]
    }
   ],
   "source": [
    "!python keras-retinanet/keras_retinanet/bin/convert_model.py \\\n",
    "    'snapshots/resnet50_csv_20.h5' \\\n",
    "    'snapshots/inference_model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83798da",
   "metadata": {},
   "source": [
    "## Загрузка необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "384e611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import imageio\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from keras_retinanet.models import load_model\n",
    "from keras_retinanet.utils.image import preprocess_image, resize_image\n",
    "from keras_retinanet.utils.colors import label_color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805852f5",
   "metadata": {},
   "source": [
    "## Загрузка модели для инференса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "344df3b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at snapshots/inference_model.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msnapshots/inference_model.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackbone_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresnet50\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras_retinanet\\models\\__init__.py:87\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, backbone_name)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m\"\"\" Loads a retinanet model using the correct custom objects.\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03mArgs\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03m    ValueError: In case of an invalid savefile.\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackbone_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\saving\\save.py:206\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    205\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    208\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(filepath_str, \u001b[38;5;28mcompile\u001b[39m, options)\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at snapshots/inference_model.h5"
     ]
    }
   ],
   "source": [
    "model = load_model('snapshots/inference_model.h5', backbone_name='resnet50')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3c3c23",
   "metadata": {},
   "source": [
    "## Загрузка словаря с метками классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81d8892b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Sea turtles'}\n"
     ]
    }
   ],
   "source": [
    "labels_to_names = {}\n",
    "with open('classes.csv') as f:\n",
    "    for line in f:\n",
    "        cls_name, cls_id = line.split(',')\n",
    "        labels_to_names[int(cls_id.strip())] = cls_name.strip()\n",
    "print(labels_to_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66f55d2",
   "metadata": {},
   "source": [
    "## Функция применения модели для детектирования объектов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb075164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(image):    \n",
    "    image_processed = preprocess_image(image[:,:,::-1].copy())\n",
    "    image_processed, scale = resize_image(image_processed)\n",
    "\n",
    "    start = time.time()\n",
    "    boxes, scores, labels = model.predict(image_processed[None, ...])\n",
    "    print(\"Processing time: \", time.time() - start)\n",
    "    boxes /= scale\n",
    "    return boxes[0], scores[0], labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af96b94",
   "metadata": {},
   "source": [
    "## Функция визуализации результатов детектирования объектов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f8de058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_predictions(image, predictions=None):\n",
    "    draw = image.copy()\n",
    "    fig, ax = plt.subplots(1, figsize=(12, 12))\n",
    "    ax.imshow(draw)\n",
    "\n",
    "    if predictions is None:\n",
    "        return\n",
    "        \n",
    "    boxes, scores, labels = predictions\n",
    "    SCORE_THRESHOLD = 0.5\n",
    "    for box, score, label in zip(boxes, scores, labels):\n",
    "        if score < SCORE_THRESHOLD:\n",
    "            break\n",
    "\n",
    "        box_y = int(box[1])\n",
    "        box_x = int(box[0])\n",
    "        box_h = int(box[3]-box[1])\n",
    "        box_w = int(box[2]-box[0])\n",
    "        caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
    "        if 0:\n",
    "            color = [x/255 for x in label_color(label)]\n",
    "        else:\n",
    "            color =  [(0, 1, 0), (1, 1, 0), (1, 0, 1), (1, 0, 0)][label]\n",
    "\n",
    "        label_size = 20\n",
    "        plt_scale = float(fig.get_size_inches()[1]) * fig.dpi * draw.shape[0] * label_size / 12545280\n",
    "        ax.add_patch(patches.Rectangle((box_x, box_y), \n",
    "                                 box_w, box_h, \n",
    "                                 linewidth=2, edgecolor=color, facecolor='none'))\n",
    "        ax.add_patch(patches.Rectangle((box_x, box_y-round(26*plt_scale)), \n",
    "                                 round(plt_scale*len(caption)*14), round(26*plt_scale), \n",
    "                                 linewidth=2, edgecolor=color, facecolor=color))\n",
    "        ax.text(box_x + round(3*plt_scale), box_y - round(5*plt_scale), caption, fontsize=label_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f132a627",
   "metadata": {},
   "source": [
    "## Детектирование объектов на тестовом изображении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c117ca43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_9312\\320747328.py:1: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning dissapear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread('./content/oidv4-sea-turtles/TEST/1ac6dffa6bbf5ac8.jpg')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m image \u001b[38;5;241m=\u001b[39m imageio\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./content/oidv4-sea-turtles/TEST/1ac6dffa6bbf5ac8.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m draw_predictions(image, predictions)\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mdetect_objects\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m      3\u001b[0m image_processed, scale \u001b[38;5;241m=\u001b[39m resize_image(image_processed)\n\u001b[0;32m      5\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 6\u001b[0m boxes, scores, labels \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(image_processed[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing time: \u001b[39m\u001b[38;5;124m\"\u001b[39m, time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start)\n\u001b[0;32m      8\u001b[0m boxes \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m scale\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "image = imageio.imread('./content/oidv4-sea-turtles/TEST/1ac6dffa6bbf5ac8.jpg')\n",
    "predictions = detect_objects(image)\n",
    "draw_predictions(image, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
